[
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-1.5B 是 Deepseek 团队研发的语言模型，约15亿参数，属于Deepseek-R1模型系列中的轻量级版本，适合基础任务和低资源环境。",
    "id": "93c6229213ab5b6891c17a2b9800a7cf",
    "name": "deepseek-r1:1.5b",
    "ollama_id": "a42b25d8c10a",
    "params_size": 1.5,
    "flavor": "deepseek",
    "api_flavor": "ollama",
    "size": "1.1GB",
    "service_source": "local",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-7B 是一款 Deepseek 团队研发的模型，主要用于大模型推理场景，具有70亿参数，适用于多种应用场景。",
    "id": "91eb560abe4b6ce0fc1057e73f5b968c",
    "name": "deepseek-r1:7b",
    "ollama_id": "0a8c26691023",
    "params_size": 7,
    "flavor": "deepseek",
    "size": "4.7GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "‌Deepseek-r1-8B‌是一款基于 Llama 架构的语言模型，拥有80亿的参数数量，经过深度蒸馏处理，使得模型在复杂的自然语言处理任务中表现出色，同时节省计算资源‌。",
    "id": "380e92fef2534ccf3af5fa62a2cf9d1c",
    "name": "deepseek-r1:8b",
    "ollama_id": "28f8fd6cdc67",
    "params_size": 8,
    "flavor": "deepseek",
    "size": "4.9GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-14B 是 Deepseek 团队研发的大规模语言模型，其参数量达到140亿。该模型在自然语言处理任务中表现出色，能够提供高质量的语言理解和生成能力。",
    "id": "ba1a60e5099a931336582a4d45dcfad0",
    "name": "deepseek-r1:14b",
    "ollama_id": "ea35dfe18182",
    "params_size": 14,
    "flavor": "deepseek",
    "size": "9.0GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-0.5B 是aliyun通义千问团队推出的第三代小参数模型，约5亿参数，属于轻量级模型‌，提供代码生成、文本理解等核心能力，适合轻量级自然语言任务。‌",
    "id": "f2506e790b637a02071d9b07c861204f",
    "name": "qwen2.5:0.5b",
    "ollama_id": "a8b0c5157701",
    "params_size": 0.5,
    "flavor": "aliyun",
    "size": "398MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-1.5B 是aliyun通义千问团队推出的第三代轻量级模型，约15亿参数，在保持轻量化的同时，通过架构优化与数据扩展实现了与更大规模模型相近的推理能力。",
    "id": "b314148783aa11c0a5b133ffe5d372bf",
    "name": "qwen2.5:1.5b",
    "ollama_id": "65ec06548149",
    "params_size": 1.5,
    "flavor": "aliyun",
    "size": "986MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-3B 是aliyun通义千问团队推出的第三代模型，约30亿参数，覆盖中文、英文、日文等 29 种语言，在保持端侧部署优势的同时，通过架构优化实现了与 7B 参数模型相近的任务处理能力‌。",
    "id": "59a49530e9bf5eb00967e63d147762d0",
    "name": "qwen2.5:3b",
    "ollama_id": "357c53fb659c",
    "params_size": 3,
    "flavor": "aliyun",
    "size": "1.9GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-7B 是aliyun通义千问团队推出的第三代模型，约70亿参数，在长文本处理、多语言支持和专业领域任务中展现了与更大规模模型相近的性能，是平衡算力成本与任务精度的优选方案。",
    "id": "2aecc3c035289c2b6b30bc92cf9db3a5",
    "name": "qwen2.5:7b",
    "ollama_id": "845dbda0ea48",
    "params_size": 7,
    "flavor": "aliyun",
    "size": "4.7GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-14B 是aliyun通义千问团队推出的第三代大模型，约147亿参数，支持多语言，在数学推理、代码生成和多语言任务中表现卓越。",
    "id": "aa9604e15ba4d636e97569ada6d6bb54",
    "name": "qwen2.5:14b",
    "ollama_id": "7cdf5a0187d5",
    "params_size": 14,
    "flavor": "aliyun",
    "size": "9.0GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "deepscaler-1.5B 是基于 ‌Deepseek-R1-Distilled-Qwen-1.5B 通过强化学习微调优化的语言模型，约15亿参数，适用于轻量化设备部署与实时交互场景。",
    "id": "c51d4326747b182143e136b0c6f222a0",
    "name": "deepscaler:1.5b",
    "ollama_id": "0031bcf7459f",
    "params_size": 1.5,
    "flavor": "deepseek",
    "size": "3.6GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-0.5B 是aliyun通义千问团队推出的编程向第三代模型，约5亿参数，基于 Qwen2.5 架构‌与 Transformer 解码器‌设计，支持 Python 等92种编程语言。",
    "id": "aa94725f9e57f4ce77a84ac2114b7e55",
    "name": "qwen2.5-coder:0.5b",
    "ollama_id": "d392ed348d5b",
    "params_size": 0.5,
    "flavor": "aliyun",
    "size": "531MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-1.5B 是aliyun通义千问团队推出的编程向第三代模型，约15亿参数，支持 92 种编程语言，针对轻量化设备提供高效代码生成、补全与修复能力。",
    "id": "6d26698a0338dff9f08640914fd77688",
    "name": "qwen2.5-coder:1.5b",
    "ollama_id": "6d3abb8d2d53",
    "params_size": 1.5,
    "flavor": "aliyun",
    "size": "986MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-3B 是aliyun通义千问团队推出的编程向第三代模型，约30亿参数，基于 Qwen2.5 架构‌与 Transformer 解码器‌设计，重点增强多语言代码生成与优化能力，适用于中等复杂度编程任务。",
    "id": "edbe40f004fb51aa9dbfade1b7838d8c",
    "name": "qwen2.5-coder:3b",
    "ollama_id": "e7149271c296",
    "params_size": 3,
    "flavor": "aliyun",
    "size": "1.9GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-7B 是aliyun通义千问团队推出的编程向第三代模型，约70亿参数，支持 92 种编程语言，重点提升代码推理与修复能力，适用于复杂编程任务。",
    "id": "31aa5e78cbe0834e1415024fc5ac70d8",
    "name": "qwen2.5-coder:7b",
    "ollama_id": "2b0496514337",
    "params_size": 7,
    "flavor": "aliyun",
    "size": "4.7GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-14B 是aliyun通义千问团队推出的编程向第三代大模型，约140亿参数，支持 92 种编程语言，重点优化大型代码库协同开发与复杂逻辑推理能力。",
    "id": "4b6216b1f7bceb513c301d57e6e8aa91",
    "name": "qwen2.5-coder:14b",
    "ollama_id": "3028237cc8c5",
    "params_size": 14,
    "flavor": "aliyun",
    "size": "9.0GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/yi.png",
    "class": [
      "文本生成"
    ],
    "description": "yi-coder-1.5B 是零一万物开源的 1.5 亿参数‌编程助手模型‌，支持52种编程语言‌‌，擅长代码生成、代码补全和调试任务‌。",
    "id": "1f7d5706542577eeb616f21668c9b71b",
    "name": "yi-coder:1.5b",
    "ollama_id": "186c460ee707",
    "params_size": 1.5,
    "flavor": "Yi",
    "size": "866MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/yi.png",
    "class": [
      "文本生成"
    ],
    "description": "yi-coder-9B 是零一万物开源的90亿参数‌代码模型‌，支持52种编程语言‌‌，在代码生成、调试与补全任务中性能超越同规模模型，适用于复杂项目级开发‌。",
    "id": "8b9253e16efb76e8873452da8c9f2b25",
    "name": "yi-coder:9b",
    "ollama_id": "39c63e7675d7",
    "params_size": 9,
    "flavor": "Yi",
    "size": "5.0GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-math-1.5B 是aliyun通义千问团队推出的数学与推理向第二代模型，约15亿参数，适用于多步逻辑推理与竞赛数学题求解‌。",
    "id": "b62312f6dec69901617a05488104adb1",
    "name": "qwen2-math:1.5b",
    "ollama_id": "a4fdda0c6cc5",
    "params_size": 1.5,
    "flavor": "aliyun",
    "size": "935MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-math-7B 是aliyun通义千问团队推出的数学与推理向第二代模型，约70亿参数，擅长多步逻辑推理与竞赛数学题求解‌，支持中英双语数学问题解析‌。",
    "id": "26358a16571acdeb4beb87b250960167",
    "name": "qwen2-math:7b",
    "ollama_id": "28cc3a337734",
    "params_size": 7,
    "flavor": "aliyun",
    "size": "4.4GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/glm.png",
    "class": [
      "文本生成"
    ],
    "description": "glm4:9B 是清华zhipuAi开源的90亿参数‌多模态对话模型‌,支持26种语言,具备代码执行、网页浏览及多模态交互能力‌。",
    "id": "6d76074f008639409d168f5bb022a866",
    "name": "glm4:9b",
    "ollama_id": "5b699761eca5",
    "params_size": 9,
    "flavor": "zhipuAi",
    "size": "5.5GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-coder-v2:16B 是深度求索推出的160亿参数‌代码大模型‌，支持338种编程语言‌的代码生成与理解任务‌。",
    "id": "a9e9a4a8bd58856857f711efe575971c",
    "name": "deepseek-coder-v2:16b",
    "ollama_id": "63fb193b3a9b",
    "params_size": 14,
    "flavor": "deepseek",
    "size": "8.9GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-0.5B 是aliyun通义千问团队推出的第二代模型，约5亿参数，面向入门级应用和小型任务开发‌。",
    "id": "c854397c3812a32dfd4f53acec834307",
    "name": "qwen2:0.5b",
    "ollama_id": "6f48b936a09f",
    "params_size": 0.5,
    "flavor": "aliyun",
    "size": "352MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-1.5B 是aliyun通义千问团队推出的第二代模型，约15亿参数，擅长文本分类、数学推理等任务‌。",
    "id": "32138731844590a1cd8aff63cf394045",
    "name": "qwen2:1.5b",
    "ollama_id": "f6daf2b25194",
    "params_size": 1.5,
    "flavor": "aliyun",
    "size": "935MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-7B 是aliyun通义千问团队推出的第二代模型，约70亿参数，支持 ‌27 种语言。",
    "id": "c3320719030abce5a9e9b41bed066efe",
    "name": "qwen2:7b",
    "ollama_id": "dd314f039b9d",
    "params_size": 7,
    "flavor": "aliyun",
    "size": "4.4GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-v2:16B 是 Deepseek 团队开发的升级版大语言模型，约160亿参数，擅长代码生成、数学推理等任务‌。",
    "id": "857f99b15c3d01bde9e6d32cbd507107",
    "name": "deepseek-v2:16b",
    "ollama_id": "7c8c332f2df7",
    "params_size": 16,
    "flavor": "deepseek",
    "size": "8.9GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "codeQwen-7B 是aliyun通义千问团队推出的编程模型，约70亿参数，支持多语言编程，作为通义灵码的核心技术底座提供高效编程辅助‌。",
    "id": "6319a5eacf0ae32413766f84d60e96df",
    "name": "codeqwen:7b",
    "ollama_id": "df352abf55b1",
    "params_size": 7,
    "flavor": "aliyun",
    "size": "4.2GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-0.5B 是aliyun通义千问团队推出的轻量级模型，约5亿参数，专为低成本部署设计，适用于入门级AI应用场景‌。",
    "id": "91279958e21232c484ee42734338476f",
    "name": "qwen:0.5b",
    "ollama_id": "b5dc5e784f2a",
    "params_size": 0.5,
    "flavor": "aliyun",
    "size": "395MB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-1.8B 是aliyun通义千问团队推出的模型，约18亿参数，具备多语言处理能力‌与‌稀疏注意力机制‌‌，适用于轻量化场景下的文本生成、问答等任务‌。",
    "id": "12d72fc87adf8d0d8fab3a52bb3bbf55",
    "name": "qwen:1.8b",
    "ollama_id": "b6e8ec2e7126",
    "params_size": 1.8,
    "flavor": "aliyun",
    "size": "1.1GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-4B 是aliyun通义千问团队推出的模型，约40亿参数，支持多语言，适用于本地化代码生成、文档分析等中等负载场景‌。",
    "id": "971a0982fb711a55b59ceec2213d4adb",
    "name": "qwen:4b",
    "ollama_id": "d53d04290064",
    "params_size": 4,
    "flavor": "aliyun",
    "size": "2.3GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-7B 是aliyun通义千问团队推出的模型，约70亿参数，适用于文本生成、智能问答及本地化知识库构建等中高负载场景‌。",
    "id": "7ce0d24481adb4247fd67f5140ab14cf",
    "name": "qwen:7b",
    "ollama_id": "2091ee8c8d8f",
    "params_size": 7,
    "flavor": "aliyun",
    "size": "4.5GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-llm-7B 是 Deepseek 团队开发的中文/多语言大模型，约70亿参数，在数学推理、代码生成等任务中表现优异‌。",
    "id": "bae235e097e8d8f8cf85a0bf839a89e6",
    "name": "deepseek-llm:7b",
    "ollama_id": "9aab369a853b",
    "params_size": 7,
    "flavor": "deepseek",
    "size": "4.0GB",
    "service_source": "local",
    "api_flavor": "ollama",
    "service_name": "chat"
  },
  {
    "name": "ernie-3.5-8k",
    "description": "",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/baidu.png",
    "input_length": 8000,
    "output_length": 5000,
    "flavor": "baidu",
    "service_source": "remote",
    "api_flavor": "baidu",
    "service_name": "chat"
  }, {
  "name": "qwen-max",
  "description": "通义千问系列效果最好的模型，适合复杂、多步骤的任务。",
  "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
  "class": ["文本生成"],
  "flavor": "aliyun",
  "max_input": 30720,
  "max_output": 8192,
  "service_source": "remote",
  "api_flavor": "aliyun",
  "service_name": "chat"
},
  {
    "name": "qwen-plus",
    "description": "基于 Qwen2.5 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 129024,
    "max_output": 8192,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "chat"
  },
  {
    "name": "qwen-turbo",
    "description": "通义千问系列速度最快、成本极低的模型，适合简单任务。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 1000000,
    "max_output": 1000000,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "chat"
  },
  {
    "name": "qwen-long",
    "description": "通义千问系列上下文窗口最长，能力均衡且成本较低的模型，适合长文本分析、信息抽取、总结摘要和分类打标等任务。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 10000000,
    "max_output": 10000000,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "chat"
  },
  {
    "name": "hunyuan-turbo",
    "description": "通义千问系列上下文窗口最长，能力均衡且成本较低的模型，适合长文本分析、信息抽取、总结摘要和分类打标等任务。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
    "flavor": "tencent",
    "max_input": 28000,
    "max_output": 4000,
    "service_source": "remote",
    "api_flavor": "tencent",
    "service_name": "chat"
  },
  {
    "name": "hunyuan-t1-latest",
    "description": "业内首个超大规模 Hybrid-Transformer-Mamba 推理模型，扩展推理能力，超强解码速度，进一步对齐人类偏好。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
    "flavor": "tencent",
    "max_input": 28000,
    "max_output": 64000,
    "service_source": "remote",
    "api_flavor": "tencent",
    "service_name": "chat"
  },
  {
    "name": "hunyuan-large",
    "description": "Hunyuan-large 模型总参数量约 389B，激活参数量约 52B，是当前业界参数规模最大、效果最好的 Transformer 架构的开源 MoE 模型。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
    "flavor": "tencent",
    "max_input": 28000,
    "max_output": 4000,
    "service_source": "remote",
    "api_flavor": "tencent",
    "service_name": "chat"
  },
  {
    "name": "hunyuan-standard",
    "description": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。\nMOE-32K 性价比相对更高，在平衡效果、价格的同时，可实现对长文本输入的处理。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
    "flavor": "tencent",
    "max_input": 30000,
    "max_output": 2000,
    "service_source": "remote",
    "api_flavor": "tencent",
    "service_name": "chat"
  },
  {
    "name": "hunyuan-turbos-latest",
    "description": "统一数学解题步骤的风格，加强数学多轮问答。\n文本创作优化回答风格，去除AI味，增加文采。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
    "flavor": "tencent",
    "max_input": 24000,
    "max_output": 8000,
    "service_source": "remote",
    "api_flavor": "tencent",
    "service_name": "chat"
  },
  {
    "name": "deepseek-resoning",
    "description": "deepseek-resoning是 DeepSeek 推出的推理模型。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。我们的 API 向用户开放 deepseek-reasoner 思维链的内容，以供用户查看、展示、蒸馏使用。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "flavor": "deepseek",
    "max_input": 64000,
    "max_output": 64000,
    "service_source": "remote",
    "api_flavor": "deepseek",
    "service_name": "chat"
  },
  {
    "name": "deepseek-chat",
    "description": "deepseek-resoning是 DeepSeek 推出的对话模型（deepseek-v3）。",
    "class": ["文本生成"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/deepseek.png",
    "flavor": "deepseek",
    "max_input": 0,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "deepseek",
    "service_name": "chat"
  },
  {
    "name": "hunyuan-embedding",
    "description": "",
    "class": ["文本向量化"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
    "flavor": "tencent",
    "max_input": 0,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "tencent",
    "service_name": "embed"
  },
  {
    "name": "embedding-v1",
    "description": "",
    "class": ["文本向量化"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/baidu.png",
    "flavor": "baidu",
    "max_input": 384,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "baidu",
    "service_name": "embed"
  },
  {
    "name": "text-embedding-v1",
    "description": "",
    "class": ["文本向量化"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 512000,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "embed"
  },
  {
    "name": "text-embedding-v2",
    "description": "",
    "class": ["文本向量化"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 512000,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "embed"
  },
  {
    "name": "text-embedding-v3",
    "description": "",
    "class": ["文本向量化"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 81920,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "embed"
  },
  {
    "name": "wanx2.1-t2i-turbo",
    "description": "生成速度快、效果全面、性价比高。对应通义万相官网2.1极速模型。",
    "class": ["文生图"],
    "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
    "flavor": "aliyun",
    "max_input": 0,
    "max_output": 0,
    "service_source": "remote",
    "api_flavor": "aliyun",
    "service_name": "text_to_image"
  }, {
  "name": "wanx2.1-t2i-plus",
  "description": "生成图像细节更丰富，速度较慢。对应通义万相官网2.1专业模型。",
  "class": ["文生图"],
  "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
  "flavor": "aliyun",
  "max_input": 0,
  "max_output": 0,
  "service_source": "remote",
  "api_flavor": "aliyun",
  "service_name": "text_to_image"
  
}, {
  "name": "wanx2.0-t2i-turbo",
  "description": "擅长质感人像，速度中等、成本较低。对应通义万相官网2.0极速模型。",
  "class": ["文生图"],
  "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/aliyun.png",
  "flavor": "aliyun",
  "max_input": 0,
  "max_output": 0,
  "service_source": "remote",
  "api_flavor": "aliyun",
  "service_name": "text_to_image"
}, {
  "name": "irag-1.0",
  "description": "",
  "class": ["文生图"],
  "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/baidu.png",
  "flavor": "baidu",
  "max_input": 200,
  "max_output": 0,
  "service_source": "remote",
  "api_flavor": "baidu",
  "service_name": "text_to_image"
}, {
  "name": "hunyuan-DiT",
  "description": "",
  "class": ["文生图"],
  "avatar": "http://120.232.136.73:31619/byzedev/model_avatar/tencent.png",
  "flavor": "tencent",
  "max_input": 0,
  "max_output": 0,
  "service_source": "remote",
  "api_flavor": "tencent",
  "service_name": "text_to_image"
}
]