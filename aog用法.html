

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>如何使用 Oadin &mdash; Oadin (AIPC Open Gateway) v0.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=4b4c264b" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=683873e3"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Oadin (AIPC Open Gateway)
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Oadin 目标:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="%E4%BB%8B%E7%BB%8D.html">Oadin针对的问题陈述</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Oadin API 规范:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="service_specs/chat.html">Oadin Chat 服务相关</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Oadin (AIPC Open Gateway)</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">如何使用 Oadin</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/aog用法.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="oadin">
<h1>如何使用 Oadin<a class="headerlink" href="#oadin" title="Link to this heading"></a></h1>
<p>Oadin 是一个运行时，旨在为开发者提供一个极其简单易用的基础设施，以便他们在开发环境中安装本地 AI 服务，并发布他们的 AI 应用程序，无需打包自己的 AI 堆栈和模型。</p>
digraph G {
  rankdir=TB
  compound=true
  label = &quot;Application Utilizing Oadin&quot;
  graph [fontname = &quot;Verdana&quot;, fontsize = 10, style=&quot;filled&quot;, penwidth=0.5]
  node [fontname = &quot;Verdana&quot;, fontsize = 10, shape=box, color=&quot;#333333&quot;, style=&quot;filled&quot;, penwidth=0.5]


  subgraph cluster_aipc {
     label = &quot;AIPC&quot;
     color=&quot;#dddddd&quot;
     fillcolor=&quot;#eeeeee&quot;

     app_a[label=&quot;Application A&quot;, fillcolor=&quot;#eeeeff&quot;]
     app_b[label=&quot;Application B&quot;, fillcolor=&quot;#eeeeff&quot;]
     app_c[label=&quot;Application C&quot;, fillcolor=&quot;#eeeeff&quot;]

     oadin[label=&quot;Oadin API Layer&quot;, fillcolor=&quot;#ffffcc&quot;]


     subgraph cluster_service {
         label = &quot;Oadin AI Service Providers&quot;
         color = &quot;#333333&quot;
         fillcolor=&quot;#ffcccc&quot;

         models[label=&quot;AI Models&quot;, fillcolor=&quot;#eeffcc&quot;]
     }

     {app_a, app_b, app_c} -&gt; oadin
     oadin -&gt; models[lhead=cluster_service, minlen=2]
  }
  cloud[label=&quot;Cloud AI Service Providers&quot;, fillcolor=&quot;#ffcccc&quot;]
  oadin -&gt; cloud[minlen=2 style=&quot;dashed&quot;]



}<p>如图所示，Oadin 提供平台级的 AI 服务，因此多个共存 AI 应用无需冗余地部署和启动自己的 AI 栈。这显著减少了应用大小，消除了每个应用重复下载相同 AI 栈和模型的情况，并在执行过程中避免了内存消耗的竞争。</p>
<p>Oadin 提供以下基本功能：</p>
<ul>
<li><p><strong>一站式 AI 服务安装</strong></p>
<p>在开发过程中，开发者可以通过简单的命令如 <code class="docutils literal notranslate"><span class="pre">oadin</span> <span class="pre">install</span> <span class="pre">chat</span></code> 或 <code class="docutils literal notranslate"><span class="pre">oadin</span> <span class="pre">pull-model</span> <span class="pre">deepseek-r1:1.5b</span> <span class="pre">for</span> <span class="pre">chat</span></code> ，
在他们的开发环境中本地安装 AI 服务。Oadin 会自动下载并安装最合适和优化的 AI 堆栈（例如 ollama）和模型。</p>
<p>在部署过程中，开发者可以无需打包依赖的 AI 栈和模型即可发布他们的 AI 应用程序。Oadin 将在需要时自动为部署的 PC 拉取所需的 AI 栈和模型。</p>
</li>
<li><p><strong>解耦应用程序和 AI 服务提供商，通过共享服务和标准 API</strong></p>
<p>Oadin API 层提供了标准化 API，用于典型 AI 服务如聊天、嵌入等。开发者专注于其应用程序的业务逻辑，无需过多关注底层 AI 服务栈。</p>
<p>AI 服务按平台提供，由同一系统上的多个应用程序共享。这避免了每个应用程序重复下载相同的 AI 服务栈和模型，减少了内存消耗的竞争。</p>
</li>
<li><p><strong>自动 API 转换，适配流行的 API 风格</strong></p>
<p>此外，Oadin API 层还提供在流行的 API 风格（例如 OpenAI API）与 Oadin 提供的 AI 服务之间的自动 API 转换。</p>
<p>这样一来，开发者可以轻松地将现有的基于云 AI 的应用程序迁移到基于 Oadin 的 AIPC 应用程序。</p>
</li>
<li><p><strong>本地与云 AI 服务提供商之间的混合调度</strong></p>
<p>Oadin 允许开发者在本地开发环境中安装 AI 服务。这些服务可以通过 Oadin API 层进行访问。</p>
</li>
</ul>
<section id="id1">
<h2>构建 Oadin 命令行工具<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<p>作为开发者，为了构建 Oadin，您需要在您的系统上安装 <a class="reference external" href="https://go.dev/">golang</a> 。</p>
<p>如果您的开发环境是 Windows，您可能需要安装 <a class="reference external" href="https://www.msys2.org/">MSYS2</a> ，以获得 Make 等命令。</p>
<p>接着，将此项目下载或克隆到如 <code class="docutils literal notranslate"><span class="pre">/path_to_oadin</span></code> 的目录中。</p>
<p>然后运行以下命令：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path_to_oadin

make<span class="w"> </span>build-all
</pre></div>
</div>
<p>这将生成一个名为 <code class="docutils literal notranslate"><span class="pre">oadin</span></code> 的可执行文件，它是 Oadin 的命令行。</p>
</section>
<section id="id2">
<h2>使用 Oadin 命令行工具<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<p>您可以通过输入  <code class="docutils literal notranslate"><span class="pre">oadin</span> <span class="pre">-h</span></code> 来查看命令行工具的帮助信息。</p>
<p>使用以下命令启动和停止 Oadin 服务</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 前台启动Oadin</span>
oadin<span class="w"> </span>server<span class="w"> </span>start

<span class="c1"># 后台启动Oadin</span>
oadin<span class="w"> </span>server<span class="w"> </span>start<span class="w"> </span>-d

<span class="c1"># 停止Oadin</span>
oadin<span class="w"> </span>server<span class="w"> </span>stop
</pre></div>
</div>
<p>Oadin 有两个关键概念：<strong>服务(Service)</strong> 和 <strong>服务提供商(Service Provider)</strong>：</p>
<ul class="simple">
<li><p>服务是一组 AI 功能，例如聊天 (chat)、嵌入(embed) 等，提供 RESTful 接口供应用程序调用使用。</p></li>
<li><p>服务提供商是实现并提供服务的具体实体。服务提供商可以是本地或远程的。</p></li>
</ul>
<p>一个服务可以有多个服务提供商。例如，聊天服务可以同时有本地聊天服务提供商和远程聊天服务提供商。  其中本地服务提供商由ollama
提供，远程服务提供商由远程的DeepSeek或者通义千问提供。当应用程序使用 Oadin 的 RESTful API 调用聊天服务的时候，Oadin会根据一定的规则，
自动选择合适的服务提供商，来完成该服务的真正调用。</p>
<p>作为开发者，可以通过如下命令来快速安装、导入和配置相应的 Oadin 服务和服务提供商</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 将 AI 服务安装到本地</span>
<span class="c1"># Oadin 将安装必要的 AI 堆栈（如 ollama）和 Oadin 推荐的模型</span>
oadin<span class="w"> </span>install<span class="w"> </span>chat
oadin<span class="w"> </span>install<span class="w"> </span>embed

<span class="c1"># 除了默认的模型之外，您可以在服务中安装更多的模型</span>
<span class="c1"># 当前版本暂仅支持基于 ollama 拉取模型</span>
<span class="c1"># v0.3 版本将支持更多的 AI 堆栈和模型，以及其他服务</span>
oadin<span class="w"> </span>pull<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span>-for<span class="w"> </span>&lt;service_name&gt;<span class="w"> </span>--provider<span class="w"> </span>&lt;provider_name&gt;

<span class="c1"># 获取服务信息，可查看指定服务，未指定则输出全部服务信息</span>
oadin<span class="w"> </span>get<span class="w"> </span>services<span class="w"> </span>&lt;service_name&gt;


<span class="c1"># 修改服务配置</span>
<span class="c1"># hybrid_policy 指定具体服务的调度策略，可选值有 always_local, always_remote, default</span>
<span class="c1"># remote_provider 指定远程服务提供商</span>
<span class="c1"># local_provider 指定本地服务提供商</span>
oadin<span class="w"> </span>edit<span class="w"> </span>service<span class="w"> </span>&lt;service_name&gt;<span class="w"> </span>--hybrid_policy<span class="w"> </span>always_remote<span class="w"> </span>--remote_provider<span class="w"> </span>xxx<span class="w"> </span>--local_provider<span class="w"> </span>xxx


<span class="c1"># 获取服务提供商信息，可设置可选参来获取指定服务提供商信息</span>
oadin<span class="w"> </span>get<span class="w"> </span>service_providers<span class="w"> </span>--service<span class="w"> </span>&lt;service_name&gt;<span class="w"> </span>--provider<span class="w"> </span>&lt;provider_name&gt;<span class="w"> </span>--remote<span class="w"> </span>&lt;local/remote&gt;

<span class="c1"># 获取模型信息，可设置可选参获取指定模型信息</span>
oadin<span class="w"> </span>get<span class="w"> </span>models<span class="w"> </span>--provider<span class="w"> </span>&lt;provider_name&gt;

<span class="c1"># 安装服务提供商， 安装过程中会自动拉取模型</span>
oadin<span class="w"> </span>install<span class="w"> </span>service_provider<span class="w"> </span>-f<span class="w"> </span>xx/xxx.json
<span class="c1"># 文件名不作要求，内容需为json格式，示例：</span>
<span class="o">{</span>
<span class="w">    </span><span class="s2">&quot;provider_name&quot;</span>:<span class="w"> </span><span class="s2">&quot;local_ollama_chat&quot;</span>
<span class="w">    </span><span class="s2">&quot;service_name&quot;</span>:<span class="w"> </span><span class="s2">&quot;chat&quot;</span>,
<span class="w">    </span><span class="s2">&quot;service_source&quot;</span>:<span class="w"> </span><span class="s2">&quot;local&quot;</span>,
<span class="w">    </span><span class="s2">&quot;desc&quot;</span>:<span class="w"> </span><span class="s2">&quot;Local ollama chat/completion&quot;</span>,
<span class="w">    </span><span class="s2">&quot;api_flavor&quot;</span>:<span class="w"> </span><span class="s2">&quot;ollama&quot;</span>,
<span class="w">    </span><span class="s2">&quot;method&quot;</span>:<span class="w"> </span><span class="s2">&quot;POST&quot;</span>,
<span class="w">    </span><span class="s2">&quot;url&quot;</span>:<span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/chat&quot;</span>,
<span class="w">    </span><span class="s2">&quot;auth_type&quot;</span>:<span class="w"> </span><span class="s2">&quot;none&quot;</span>,
<span class="w">    </span><span class="s2">&quot;auth_key&quot;</span>:<span class="w"> </span><span class="s2">&quot;&quot;</span>,
<span class="w">    </span><span class="s2">&quot;models&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="s2">&quot;qwen2.5:0.5b&quot;</span>,
<span class="w">        </span><span class="s2">&quot;qwen2:0.5b&quot;</span>
<span class="w">    </span><span class="o">]</span>
<span class="o">}</span>

<span class="c1"># 修改服务提供商配置，这里仅可修改服务商配置信息，模型变更需通过拉取模型和删除模型来进行</span>
oadin<span class="w"> </span>edit<span class="w"> </span>service_provider<span class="w"> </span>&lt;provider_name&gt;<span class="w"> </span>-f<span class="w"> </span>xxx/xxx.json
<span class="c1"># 示例：</span>
<span class="o">{</span>
<span class="w">    </span><span class="s2">&quot;provider_name&quot;</span>:<span class="w"> </span><span class="s2">&quot;local_ollama_chat&quot;</span>
<span class="w">    </span><span class="s2">&quot;service_name&quot;</span>:<span class="w"> </span><span class="s2">&quot;chat&quot;</span>,
<span class="w">    </span><span class="s2">&quot;service_source&quot;</span>:<span class="w"> </span><span class="s2">&quot;local&quot;</span>,
<span class="w">    </span><span class="s2">&quot;desc&quot;</span>:<span class="w"> </span><span class="s2">&quot;Local ollama chat/completion&quot;</span>,
<span class="w">    </span><span class="s2">&quot;api_flavor&quot;</span>:<span class="w"> </span><span class="s2">&quot;ollama&quot;</span>,
<span class="w">    </span><span class="s2">&quot;method&quot;</span>:<span class="w"> </span><span class="s2">&quot;POST&quot;</span>,
<span class="w">    </span><span class="s2">&quot;url&quot;</span>:<span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/chat&quot;</span>,
<span class="w">    </span><span class="s2">&quot;auth_type&quot;</span>:<span class="w"> </span><span class="s2">&quot;none&quot;</span>,
<span class="w">    </span><span class="s2">&quot;auth_key&quot;</span>:<span class="w"> </span><span class="s2">&quot;&quot;</span>,
<span class="o">}</span>

<span class="c1"># 删除服务提供商</span>
oadin<span class="w"> </span>delete<span class="w"> </span>service_provider<span class="w"> </span>&lt;provider_name&gt;

<span class="c1"># 删除模型 必选参数：--provider</span>
oadin<span class="w"> </span>delete<span class="w"> </span>model<span class="w"> </span>&lt;model_name&gt;<span class="w">  </span>--provider<span class="w"> </span>&lt;provider_name&gt;
</pre></div>
</div>
<p>通过以下命令进行 Oadin 服务的导入导出</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 根据指定.oadin文件导入服务配置</span>
oadin<span class="w"> </span>import<span class="w"> </span>--file<span class="w"> </span>xxx/.oadin

<span class="c1"># 导出当前服务配置到指定位置</span>
<span class="c1"># 可选参：</span>
<span class="c1">#   service 指定服务，未指定则导出全部</span>
<span class="c1">#   provider 指定服务提供商，未指定则导出全部</span>
<span class="c1">#   model 指定模型，未指定则导出全部</span>
oadin<span class="w"> </span><span class="nb">export</span><span class="w"> </span>--service<span class="w"> </span>chat<span class="w"> </span>--provider<span class="w"> </span>local_ollama_chat<span class="w"> </span>--model<span class="w"> </span>--output<span class="w"> </span>./
</pre></div>
</div>
<p>服务导出的 <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件可以直接用作导入使用，也就是说，您可以从设备 <code class="docutils literal notranslate"><span class="pre">A</span></code> 上导出 <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件然后导入到设备 <code class="docutils literal notranslate"><span class="pre">B</span></code> 的 <code class="docutils literal notranslate"><span class="pre">Oadin</span></code> 中，以实现服务的快速共享。</p>
<p>导出的  <code class="docutils literal notranslate"><span class="pre">.oadin</span></code>  文件示例如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;v0.2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;services&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;local&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_ollama_models&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;hybrid_policy&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;chat&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;local&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_ollama_chat&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;remote&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;remote_deepseek_chat&quot;</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;hybrid_policy&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;embed&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;local&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_ollama_embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;hybrid_policy&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;local_ollama_chat&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Local ollama chat/completion&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/chat&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="s2">&quot;qwen2.5:0.5b&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="s2">&quot;qwen2:0.5b&quot;</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;remote_deepseek_chat&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;remote deepseek chat/completion&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;remote&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://api.lkeap.cloud.tencent.com/v1/chat/completions&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;apikey&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;xxxxxxxxxx&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="s2">&quot;deepseek-v3&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="s2">&quot;deepseek-r1&quot;</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;local_ollama_models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;List local ollama models&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;GET&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/tags&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;local_ollama_embed&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Local ollama embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="s2">&quot;quentinz/bge-large-zh-v1.5&quot;</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="oadin-api">
<h2>调用 Oadin API<a class="headerlink" href="#oadin-api" title="Link to this heading"></a></h2>
<p>Oadin API 是一个 Restful API。您可以通过与调用云 AI 服务（如 OpenAI）类似的方式调用该 API。详细的 API 规范请参见
<a class="reference internal" href="index.html#oadin-spec"><span class="std std-ref">Oadin API 规范</span></a>.</p>
<p>值得注意的是，当前Oadin预览提供了基本的 chat 等服务，下一版本将会提供文生图以及语音相关的更多服务。</p>
<p>例如，您可以使用 curl 在 Windows 上测试聊天服务。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:16688/oadin/v0.2/services/chat<span class="w">  </span>-X<span class="w"> </span>POST<span class="w"> </span>-H
<span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>-d
<span class="s2">&quot;{\&quot;model\&quot;:\&quot;deepseek-r1:7b\&quot;,\&quot;messages\&quot;:[{\&quot;role\&quot;:\&quot;user\&quot;,\&quot;content\&quot;:\&quot;why is</span>
<span class="s2">the sky blue?\&quot;}],\&quot;stream\&quot;:false}&quot;</span>
</pre></div>
</div>
<p>此外，如果您已经使用 OpenAI API 或 ollama API 等的应用程序，您无需重写调用 Oadin 的方式以符合其规范。</p>
<p>因为 Oadin 能够自动转换这些流行风格的 API，因此您只需更改端点 URL，就可以轻松迁移应用程序。</p>
<p>例如，如果您使用的是 OpenAI 的聊天完成服务，您只需将端点 URL 从 <code class="docutils literal notranslate"><span class="pre">https://api.openai.com/v1/chat/completions</span></code> 替换为
<code class="docutils literal notranslate"><span class="pre">http://localhost:16688/oadin/v0.2/api_flavors/openai/v1/chat/completions</span></code>。</p>
<p><strong>NOTE</strong> 请注意，调用 Oadin 的新 URL 位于 <code class="docutils literal notranslate"><span class="pre">api_flavors/openai</span></code> ，其余 URL 与原始 OpenAI API 相同，即 <code class="docutils literal notranslate"><span class="pre">/v1/chat/completions</span></code> 。</p>
<p>如果您使用 ollama API，可以将端点 URL 从 <code class="docutils literal notranslate"><span class="pre">https://localhost:11434/api/chat</span></code> 替换为
<code class="docutils literal notranslate"><span class="pre">http://localhost:16688/oadin/v0.2/api_flavors/ollama/api/chat</span></code> 。同样，它位于 <code class="docutils literal notranslate"><span class="pre">api_flavors/ollama</span></code> ，其余 URL 与原始 ollama API 相同，即 <code class="docutils literal notranslate"><span class="pre">/api/chat</span></code> 。</p>
</section>
<section id="oadin-ai">
<h2>发布您的基于 Oadin 的 AI 应用<a class="headerlink" href="#oadin-ai" title="Link to this heading"></a></h2>
<p>要将您的 AI 应用程序发布，您只需将应用程序与一个微小的 Oadin 组件打包，即所谓的 <code class="docutils literal notranslate"><span class="pre">Oadin</span> <span class="pre">Checker</span></code> ，在 Windows 上是 <code class="docutils literal notranslate"><span class="pre">OadinChecker.dll</span></code> 。您不需要发布 AI 堆栈或模型。</p>
<p>以 C/C++/C#应用程序为例，以下是部署基于 Oadin 的 AI 应用的步骤。</p>
<ol class="arabic simple">
<li><p>准备与您的应用程序一起的 <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件。 <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件是一个文本清单文件，用于指定应用程序所需的 AI 服务和模型。例如， <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件可能看起来像这样：</p></li>
</ol>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;v0.2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;services&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;local&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_ollama_models&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;hybrid_policy&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;chat&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;local&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_ollama_chat&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;remote&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;remote_deepseek_chat&quot;</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;hybrid_policy&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;embed&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;local&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_ollama_embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;hybrid_policy&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;service_providers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;local_ollama_chat&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Local ollama chat/completion&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/chat&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="s2">&quot;qwen2.5:0.5b&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="s2">&quot;qwen2:0.5b&quot;</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;remote_deepseek_chat&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;remote deepseek chat/completion&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;remote&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://api.lkeap.cloud.tencent.com/v1/chat/completions&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;apikey&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;xxxxxxxxxx&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="s2">&quot;deepseek-v3&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="s2">&quot;deepseek-r1&quot;</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;local_ollama_models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;List local ollama models&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;GET&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/tags&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;local_ollama_embed&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;desc&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Local ollama embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;service_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;api_flavor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://localhost:11434/api/embed&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;auth_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="s2">&quot;quentinz/bge-large-zh-v1.5&quot;</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic" start="2">
<li><p>在您的 <code class="docutils literal notranslate"><span class="pre">main()</span></code> 函数中包含 <code class="docutils literal notranslate"><span class="pre">OadinChecker.h</span></code> 并调用 <code class="docutils literal notranslate"><span class="pre">OadinInit()</span></code> 。 <code class="docutils literal notranslate"><span class="pre">OadinInit()</span></code> 将：</p>
<blockquote>
<div><ul class="simple">
<li><p>检查目标 PC 上是否已安装 Oadin。如果没有，将自动下载并安装 Oadin。</p></li>
<li><p>检查所需的 AI 服务和模型（如在 <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件中体现）是否已安装。如果没有，将自动下载并安装它们。</p></li>
</ul>
</div></blockquote>
</li>
<li><p>将应用程序与 <code class="docutils literal notranslate"><span class="pre">oadin.dll</span></code> 链接。</p></li>
<li><p>将应用程序与 <code class="docutils literal notranslate"><span class="pre">.oadin</span></code> 文件以及与您的应用程序 <code class="docutils literal notranslate"><span class="pre">.exe</span></code> 文件在同一目录下的 <code class="docutils literal notranslate"><span class="pre">OadinChecker.dll</span></code> 文件一起发布。</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>